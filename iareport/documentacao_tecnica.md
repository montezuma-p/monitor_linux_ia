# ü§ñ AI Report - Documenta√ß√£o T√©cnica

## Vis√£o Geral do Sistema

O AI Report √© um sistema de an√°lise e gera√ß√£o de relat√≥rios que utiliza intelig√™ncia artificial generativa para transformar dados brutos de monitoramento em relat√≥rios humanizados e compreens√≠veis. Ele consome os JSONs produzidos pelo Health Monitor e gera an√°lises interpretativas em formato HTML, prontas para visualiza√ß√£o em navegadores.

## Fundamentos da Arquitetura

### Integra√ß√£o com LLM

O sistema baseia-se na API Gemini do Google, especificamente utilizando o modelo gemini-2.5-flash. A escolha deste modelo equilibra capacidade de an√°lise com velocidade de resposta e custo operacional. O modelo √© invocado via SDK oficial `google-genai`, garantindo compatibilidade e acesso √†s funcionalidades mais recentes.

A autentica√ß√£o ocorre atrav√©s de API key configurada como vari√°vel de ambiente `GEMINI_API_KEY`. Esta abordagem segue as melhores pr√°ticas de seguran√ßa, evitando exposi√ß√£o de credenciais no c√≥digo-fonte e permitindo rota√ß√£o de chaves sem modifica√ß√£o de c√≥digo.

### Pipeline de Processamento

O fluxo de processamento segue uma arquitetura pipeline em cinco est√°gios distintos:

**Descoberta de Dados**: O sistema localiza automaticamente o arquivo JSON mais recente no diret√≥rio de entrada. Utiliza timestamps de cria√ß√£o de arquivo para determinar qual relat√≥rio processar, eliminando necessidade de interven√ß√£o manual.

**Carregamento e Valida√ß√£o**: O JSON √© carregado e parseado, com valida√ß√£o b√°sica de estrutura. Erros de formato ou corrup√ß√£o s√£o detectados nesta fase, prevenindo processamento de dados inv√°lidos.

**Constru√ß√£o de Prompt**: O prompt enviado √† LLM √© constru√≠do de forma estruturada, combinando o JSON de m√©tricas com instru√ß√µes detalhadas sobre o formato esperado de sa√≠da. O prompt inclui contexto sobre o papel da IA (administrador s√™nior de sistemas Linux), diretrizes de an√°lise e especifica√ß√£o precisa do schema JSON de retorno.

**Invoca√ß√£o da LLM**: O cliente Gemini √© invocado com o prompt constru√≠do. A resposta √© obtida de forma s√≠ncrona, bloqueando at√© conclus√£o da gera√ß√£o. O sistema n√£o implementa retry autom√°tico, assumindo que falhas transit√≥rias s√£o raras com a API Gemini.

**Renderiza√ß√£o HTML**: O JSON retornado pela IA √© injetado em um template HTML pr√©-definido atrav√©s de substitui√ß√£o de placeholders. O resultado √© um documento HTML autossuficiente que incorpora CSS inline para garantir renderiza√ß√£o consistente sem depend√™ncias externas.

## Engenharia de Prompt

O prompt enviado √† LLM √© meticulosamente elaborado para maximizar qualidade e consist√™ncia das respostas. Ele estabelece tr√™s componentes fundamentais:

**Persona e Contexto**: Define que a IA deve assumir o papel de um administrador de sistemas Linux experiente, criando um frame mental apropriado para interpreta√ß√£o t√©cnica dos dados. Isso influencia o tom, profundidade e foco da an√°lise gerada.

**Especifica√ß√£o de Sa√≠da**: Fornece um schema JSON detalhado que a IA deve seguir na resposta. Isso inclui estrutura de objetos, campos obrigat√≥rios, tipos esperados e exemplos de conte√∫do. A especifica√ß√£o √© suficientemente prescritiva para garantir parsabilidade, mas flex√≠vel o suficiente para permitir criatividade anal√≠tica.

**Diretrizes de An√°lise**: Instru√ß√µes sobre como interpretar os dados, que aspectos priorizar, como contextualizar n√∫meros para leigos e quando emitir alertas. Inclui orienta√ß√µes sobre tom (t√©cnico mas acess√≠vel), uso de analogias e balanceamento entre completude e concis√£o.

## Estrutura do Relat√≥rio Gerado

O JSON retornado pela IA segue uma estrutura hier√°rquica com quatro se√ß√µes principais:

**Resumo Executivo**: Texto corrido de 2-3 par√°grafos fornecendo uma vis√£o geral do estado do sistema. Deve ser compreens√≠vel para n√£o-t√©cnicos mas suficientemente preciso para t√©cnicos.

**Cart√µes de M√©tricas**: Array de objetos representando as m√©tricas mais importantes em formato de cards visuais. Cada card inclui √≠cone emoji, label descritivo, valor principal destacado e subtexto explicativo.

**Alertas**: Array de alertas identificados pela an√°lise, classificados em cr√≠ticos e warnings. Cada alerta cont√©m t√≠tulo, descri√ß√£o detalhada, tipo e recomenda√ß√µes de a√ß√£o.

**An√°lise Detalhada por Componente**: Se√ß√µes dedicadas para cada subsistema (CPU, mem√≥ria, disco, rede, sistema, logs), contendo an√°lises textuais espec√≠ficas sobre estado atual, tend√™ncias observ√°veis e observa√ß√µes relevantes.

## Template HTML

O arquivo `template.html` implementa um design responsivo e moderno, utilizando CSS Grid e Flexbox para layout. O styling √© completamente autocontido, sem depend√™ncias de frameworks CSS externos ou CDNs, garantindo que o relat√≥rio seja visualiz√°vel offline.

O template utiliza placeholders entre chaves duplas (sintaxe Mustache-like) que s√£o substitu√≠dos dinamicamente pelo conte√∫do gerado pela IA. Placeholders incluem elementos textuais, arrays que s√£o renderizados como loops e condicionais impl√≠citos atrav√©s da presen√ßa ou aus√™ncia de se√ß√µes.

A renderiza√ß√£o de se√ß√µes repetitivas como cards de m√©tricas e alertas √© feita atrav√©s de concatena√ß√£o de HTML gerado programaticamente, inserido em containers espec√≠ficos do template.

## Gerenciamento de Caminhos

O sistema opera com paths relativos ao diret√≥rio raiz do projeto, calculados dinamicamente a partir da localiza√ß√£o do script. Isso permite que o sistema funcione corretamente independente de onde seja invocado, desde que a estrutura de diret√≥rios do projeto seja mantida.

Tr√™s diret√≥rios s√£o relevantes para opera√ß√£o:

- **SCRIPT_DIR**: Diret√≥rio onde reside o pr√≥prio script reportia.py
- **PROJECT_ROOT**: Raiz do projeto, um n√≠vel acima do script
- **REPORTS_DIR**: Diret√≥rio de entrada contendo JSONs do Health Monitor
- **OUTPUT_DIR**: Diret√≥rio de sa√≠da onde HTMLs gerados s√£o salvos

## Tratamento de Erros e Valida√ß√£o

O sistema implementa valida√ß√£o em pontos cr√≠ticos do pipeline:

**Valida√ß√£o de API Key**: Antes de qualquer processamento, verifica se a vari√°vel de ambiente GEMINI_API_KEY est√° configurada. Aus√™ncia resulta em termina√ß√£o imediata com mensagem clara sobre como configurar.

**Valida√ß√£o de Entrada**: Verifica exist√™ncia de arquivos JSON no diret√≥rio de entrada. Aus√™ncia de dados resulta em mensagem informativa e termina√ß√£o graceful.

**Valida√ß√£o de Parsing**: Erros de parsing JSON (tanto do arquivo de entrada quanto da resposta da IA) s√£o capturados com mensagens espec√≠ficas sobre a natureza do problema.

**Valida√ß√£o de Diret√≥rios**: Garante que diret√≥rios de sa√≠da existam, criando-os automaticamente se necess√°rio.

## Intera√ß√£o com a API Gemini

A comunica√ß√£o com a API ocorre atrav√©s do SDK oficial, que abstrai detalhes de protocolo HTTP, autentica√ß√£o e serializa√ß√£o. O cliente √© inicializado uma vez no in√≠cio da execu√ß√£o e reutilizado para todas as chamadas.

O modelo gemini-2.5-flash √© configurado para operar em modo padr√£o, sem ajustes de temperatura, top-p ou outros hiperpar√¢metros. Isso prioriza consist√™ncia e previsibilidade das respostas.

N√£o h√° implementa√ß√£o de streaming - a resposta √© aguardada integralmente antes de prosseguir. Para os volumes de dados t√≠picos do Health Monitor, a lat√™ncia √© aceit√°vel (geralmente 2-5 segundos).

## Considera√ß√µes de Seguran√ßa

A API key √© mantida fora do c√≥digo, dependendo de configura√ß√£o de ambiente. Em ambientes de produ√ß√£o, recomenda-se uso de sistemas de gerenciamento de segredos como HashiCorp Vault ou AWS Secrets Manager.

O sistema n√£o valida ou sanitiza o conte√∫do retornado pela IA antes de injet√°-lo no HTML. Isso assume confian√ßa no modelo Gemini para n√£o gerar conte√∫do malicioso. Em ambientes de alta seguran√ßa, seria recomend√°vel implementar sanitiza√ß√£o adicional.

## Extensibilidade e Customiza√ß√£o

O template HTML pode ser personalizado para refletir identidade visual corporativa, adicionando logos, cores customizadas ou se√ß√µes adicionais. Desde que os placeholders sejam mantidos, o sistema continuar√° funcionando normalmente.

O prompt pode ser ajustado para modificar o tom, profundidade ou foco da an√°lise. Mudan√ßas no schema de sa√≠da requerem altera√ß√µes coordenadas entre o prompt e o template HTML.

Integra√ß√£o com outros LLMs √© poss√≠vel substituindo o cliente Gemini por outro compat√≠vel, desde que o formato de prompt e parsing de resposta sejam adaptados conforme necess√°rio.

## Performance e Otimiza√ß√£o

O principal gargalo de performance √© a lat√™ncia da API Gemini. Para processamento em lote de m√∫ltiplos relat√≥rios, seria ben√©fico implementar processamento paralelo com m√∫ltiplas chamadas simult√¢neas √† API, respeitando os rate limits.

O tamanho do prompt enviado √© proporcional ao tamanho do JSON de entrada. Para sistemas com coletas muito extensas, pode ser necess√°rio implementar resumo ou filtragem dos dados mais relevantes antes de enviar √† LLM.

A gera√ß√£o de HTML via substitui√ß√£o de strings √© eficiente para os tamanhos t√≠picos de relat√≥rio. Para volumes significativamente maiores, considerar uso de engines de template dedicados como Jinja2.

## Debugging e Troubleshooting

O sistema emite mensagens de status durante execu√ß√£o, permitindo acompanhar o progresso do pipeline. Mensagens incluem identifica√ß√£o do arquivo sendo processado, sucesso/falha de cada etapa e localiza√ß√£o do arquivo de sa√≠da gerado.

Em caso de falhas na API Gemini, as mensagens de erro s√£o propagadas do SDK, geralmente contendo c√≥digos de status HTTP e descri√ß√µes textuais do problema. Erros comuns incluem quota excedida, API key inv√°lida ou problemas de conectividade.

Para depura√ß√£o avan√ßada, pode ser √∫til salvar o prompt exato enviado √† API e a resposta bruta recebida, permitindo an√°lise offline do comportamento do modelo.
